{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The program recognizes faces, thus counts how many people are on an image, and with the use of method: gender, checks for the gender.\n",
    "\n",
    "### The amount of people can be checked with the use of len(faces)\n",
    "### The gender of person can be taken from confidence result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cvlib as cv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method count_people returns the number of people on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_people(image_path):\n",
    "    if 'jpg' in image_path:\n",
    "        image = plt.imread(image_path)\n",
    "        faces, confidences = cv.detect_face(image)\n",
    "    else:\n",
    "        image = cv2.imread(image_path)\n",
    "        faces, confidences = cv.detect_face(image)\n",
    "    print(f'People: {len(faces)}')\n",
    "    print(faces)\n",
    "    print(confidences)\n",
    "    return len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People: 1\n",
      "[[238, 19, 351, 161]]\n",
      "[0.9942492]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_people('draq.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method get_gender returns amount of women and men on a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(image_path):\n",
    "    \n",
    "    if 'jpg' in image_path:\n",
    "        img = plt.imread(image_path)\n",
    "        faces, confidences = cv.detect_face(img)\n",
    "    else:\n",
    "        img = cv2.imread(image_path)\n",
    "        faces, confidences = cv.detect_face(img)\n",
    "    \n",
    "    men = 0\n",
    "    women = 0\n",
    "    for f in faces:\n",
    "\n",
    "        (startX,startY) = f[0],f[1]\n",
    "        (endX,endY) = f[2],f[3]\n",
    "\n",
    "\n",
    "        cv2.rectangle(img,(startX,startY), (endX,endY), (0,255,0), 2)\n",
    "        \n",
    "        face_crop = np.copy(img[startY:endY,startX:endX])\n",
    "        \n",
    "        faces, confidences = cv.detect_gender(face_crop)\n",
    "        print (faces, confidences)\n",
    "        \n",
    "        if confidences[0] > confidences[1]:\n",
    "            men+=1\n",
    "        else:\n",
    "            women+=1\n",
    "   \n",
    "    print(f'{men} {women}')\n",
    "    #for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['man', 'woman'] [0.00100546 0.9985251 ]\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "get_gender('draq.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
